{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train_on_GPU.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HD2eueDpC7oE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1598417230275,"user_tz":-540,"elapsed":19119,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}},"outputId":"dcff04b1-cd73-4a37-80cd-f2dbc2028dbf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"coo9YpA9cdWA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598417230276,"user_tz":-540,"elapsed":19114,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}},"outputId":"c0d7ad09-54b5-4b85-9cf5-7b2049708f8e"},"source":["cd /content/drive/My\\ Drive/Transformer-master/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Transformer-master\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"epQKzhSr2eQp","colab_type":"text"},"source":["# ライブラリ読み込み"]},{"cell_type":"code","metadata":{"id":"i3fHswsx2Ur8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598417280924,"user_tz":-540,"elapsed":69757,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}},"outputId":"0fb000a4-e2ca-45c1-e829-6fbec029e6e6"},"source":["!apt install aptitude\n","!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n","!pip install mecab-python3==0.6"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-440\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n","  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n","  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n","  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n","  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n","Suggested packages:\n","  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n","  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n","  libwww-perl xapian-tools\n","The following NEW packages will be installed:\n","  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n","  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n","  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n","  libhttp-message-perl libio-html-perl libio-string-perl\n","  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n","  libsub-name-perl libtimedate-perl liburi-perl libxapian30\n","0 upgraded, 21 newly installed, 0 to remove and 35 not upgraded.\n","Need to get 3,877 kB of archives.\n","After this operation, 15.6 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n","Fetched 3,877 kB in 3s (1,250 kB/s)\n","Selecting previously unselected package aptitude-common.\n","(Reading database ... 144556 files and directories currently installed.)\n","Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n","Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n","Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n","Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n","Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n","Selecting previously unselected package libcwidget3v5:amd64.\n","Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n","Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n","Selecting previously unselected package libxapian30:amd64.\n","Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n","Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n","Selecting previously unselected package aptitude.\n","Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n","Unpacking aptitude (0.8.10-6ubuntu1) ...\n","Selecting previously unselected package libhtml-tagset-perl.\n","Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n","Unpacking libhtml-tagset-perl (3.20-3) ...\n","Selecting previously unselected package liburi-perl.\n","Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n","Unpacking liburi-perl (1.73-1) ...\n","Selecting previously unselected package libhtml-parser-perl.\n","Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n","Unpacking libhtml-parser-perl (3.72-3build1) ...\n","Selecting previously unselected package libcgi-pm-perl.\n","Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n","Unpacking libcgi-pm-perl (4.38-1) ...\n","Selecting previously unselected package libfcgi-perl.\n","Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n","Unpacking libfcgi-perl (0.78-2build1) ...\n","Selecting previously unselected package libcgi-fast-perl.\n","Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n","Unpacking libcgi-fast-perl (1:2.13-1) ...\n","Selecting previously unselected package libsub-name-perl.\n","Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n","Unpacking libsub-name-perl (0.21-1build1) ...\n","Selecting previously unselected package libclass-accessor-perl.\n","Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n","Unpacking libclass-accessor-perl (0.51-1) ...\n","Selecting previously unselected package libencode-locale-perl.\n","Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n","Unpacking libencode-locale-perl (1.05-1) ...\n","Selecting previously unselected package libtimedate-perl.\n","Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n","Unpacking libtimedate-perl (2.3000-2) ...\n","Selecting previously unselected package libhttp-date-perl.\n","Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n","Unpacking libhttp-date-perl (6.02-1) ...\n","Selecting previously unselected package libio-html-perl.\n","Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n","Unpacking libio-html-perl (1.001-1) ...\n","Selecting previously unselected package liblwp-mediatypes-perl.\n","Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n","Unpacking liblwp-mediatypes-perl (6.02-1) ...\n","Selecting previously unselected package libhttp-message-perl.\n","Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n","Unpacking libhttp-message-perl (6.14-1) ...\n","Selecting previously unselected package libio-string-perl.\n","Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n","Unpacking libio-string-perl (1.08-3) ...\n","Selecting previously unselected package libparse-debianchangelog-perl.\n","Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n","Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n","Setting up libhtml-tagset-perl (3.20-3) ...\n","Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n","Setting up libencode-locale-perl (1.05-1) ...\n","Setting up libtimedate-perl (2.3000-2) ...\n","Setting up libio-html-perl (1.001-1) ...\n","Setting up aptitude-common (0.8.10-6ubuntu1) ...\n","Setting up liblwp-mediatypes-perl (6.02-1) ...\n","Setting up liburi-perl (1.73-1) ...\n","Setting up libhtml-parser-perl (3.72-3build1) ...\n","Setting up libcgi-pm-perl (4.38-1) ...\n","Setting up libio-string-perl (1.08-3) ...\n","Setting up libsub-name-perl (0.21-1build1) ...\n","Setting up libfcgi-perl (0.78-2build1) ...\n","Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n","Setting up libclass-accessor-perl (0.51-1) ...\n","Setting up libhttp-date-perl (6.02-1) ...\n","Setting up libcgi-fast-perl (1:2.13-1) ...\n","Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n","Setting up libhttp-message-perl (6.14-1) ...\n","Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n","Setting up aptitude (0.8.10-6ubuntu1) ...\n","update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","git is already installed at the requested version (1:2.17.1-1ubuntu0.7)\n","make is already installed at the requested version (4.1-9.1ubuntu1)\n","curl is already installed at the requested version (7.58.0-2ubuntu3.10)\n","xz-utils is already installed at the requested version (5.2.2-1.3)\n","git is already installed at the requested version (1:2.17.1-1ubuntu0.7)\n","make is already installed at the requested version (4.1-9.1ubuntu1)\n","curl is already installed at the requested version (7.58.0-2ubuntu3.10)\n","xz-utils is already installed at the requested version (5.2.2-1.3)\n","The following NEW packages will be installed:\n","  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n","The following packages will be REMOVED:\n","  libnvidia-common-440{u} \n","0 packages upgraded, 11 newly installed, 1 to remove and 35 not upgraded.\n","Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n","Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n","Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n","Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n","Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n","Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n","Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n","Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n","Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n","Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n","Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n","Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n","Fetched 29.3 MB in 5s (6,425 kB/s)\n","(Reading database ... 145015 files and directories currently installed.)\n","Removing libnvidia-common-440 (440.100-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package libmagic-mgc.\n","(Reading database ... 145010 files and directories currently installed.)\n","Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package libmagic1:amd64.\n","Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package file.\n","Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking file (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package libmecab2:amd64.\n","Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n","Unpacking libmecab2:amd64 (0.996-5) ...\n","Selecting previously unselected package libmecab-dev.\n","Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n","Unpacking libmecab-dev (0.996-5) ...\n","Selecting previously unselected package mecab-utils.\n","Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n","Unpacking mecab-utils (0.996-5) ...\n","Selecting previously unselected package mecab-jumandic-utf8.\n","Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n","Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n","Selecting previously unselected package mecab-jumandic.\n","Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n","Unpacking mecab-jumandic (7.0-20130310-4) ...\n","Selecting previously unselected package mecab-ipadic.\n","Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n","Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n","Selecting previously unselected package mecab.\n","Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n","Unpacking mecab (0.996-5) ...\n","Selecting previously unselected package mecab-ipadic-utf8.\n","Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n","Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n","Setting up libmecab2:amd64 (0.996-5) ...\n","Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n","Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n","Setting up mecab-utils (0.996-5) ...\n","Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up libmecab-dev (0.996-5) ...\n","Setting up file (1:5.32-2ubuntu0.4) ...\n","Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n","Compiling Juman dictionary for Mecab.\n","reading /usr/share/mecab/dic/juman/unk.def ... 37\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n","reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n","reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n","reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n","reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n","reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n","reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n","reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n","reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n","reading /usr/share/mecab/dic/juman/Special.csv ... 158\n","reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n","reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n","reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n","reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n","reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n","reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up mecab (0.996-5) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","Setting up mecab-jumandic (7.0-20130310-4) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","                            \n","Collecting mecab-python3==0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/7f/f98371035a0171abf95f9893eabf915f8a3199d005fed3cd69cc122fed40/mecab-python3-0.6.tar.gz (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: mecab-python3\n","  Building wheel for mecab-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mecab-python3: filename=mecab_python3-0.6-cp36-cp36m-linux_x86_64.whl size=155468 sha256=ea1e08ad91f76b114076f2b89035bff1ed48ff803b57301ff0d046241409744a\n","  Stored in directory: /root/.cache/pip/wheels/4d/51/5b/987888cacaf8bb25982ef4569261f68debe85b7587c5563c79\n","Successfully built mecab-python3\n","Installing collected packages: mecab-python3\n","Successfully installed mecab-python3-0.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zYeKw9Od2UpM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598417285807,"user_tz":-540,"elapsed":74636,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}},"outputId":"96e6de46-6515-4725-f694-991c61f94990"},"source":["import numpy as np\n","import os\n","import time\n","import MeCab\n","\n","import preprocess_utils\n","import model\n","import weight_utils\n","\n","import tensorflow.keras as keras\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tI7_kf-q2jWU","colab_type":"text"},"source":["# 日英翻訳データ ダウンロード"]},{"cell_type":"code","metadata":{"id":"zQcDmN562UvU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598417285808,"user_tz":-540,"elapsed":74632,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}}},"source":["# !wget http://www.manythings.org/anki/jpn-eng.zip\n","# !unzip ./jpn-eng.zip"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UGuSp62c2o4x","colab_type":"text"},"source":["# データ読み込み"]},{"cell_type":"code","metadata":{"id":"snWWm2Jp2c4p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1598417285809,"user_tz":-540,"elapsed":74629,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}},"outputId":"3b3ec8ad-3104-41e7-8059-215ad413c1fc"},"source":["dataset = preprocess_utils.CreateData(\n","    corpus_path = './jpn.txt',\n","    do_shuffle=True,\n","    seed_value=123,\n","    split_percent=0.95 # 学習データの割合\n",")\n","\n","train_source, train_target, test_source, test_target, train_licence, test_licence = dataset.split_data()\n","\n","print('**** Amount of data ****')\n","print('train_source： ', len(train_source))\n","print('train_target： ', len(train_target))\n","print('test_source： ', len(test_source))\n","print('test_target： ', len(test_target))\n","print('\\n')\n","print('**** Train data example ****')\n","print('Source Example： ', train_source[0])\n","print('Target Example： ', train_target[0])\n","print('Licence： ', train_licence[0])\n","print('\\n')\n","print('**** Test data example ****')\n","print('Source Example： ', test_source[0])\n","print('Target Example： ', test_target[0])\n","print('Licence： ', test_licence[0])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["**** Amount of data ****\n","train_source：  52857\n","train_target：  52857\n","test_source：  2782\n","test_target：  2782\n","\n","\n","**** Train data example ****\n","Source Example：  Look after Tom.\n","Target Example：  トムの面倒を見てて。\n","Licence：  CC-BY 2.0 (France) Attribution: tatoeba.org #2782602 (CK) & #2125677 (bunbuku)\n","\n","\n","\n","**** Test data example ****\n","Source Example：  You should tell your mother as soon as possible.\n","Target Example：  できるだけ早く、お母さんに知らせたほうがいい。\n","Licence：  CC-BY 2.0 (France) Attribution: tatoeba.org #3554418 (CK) & #3553337 (arnab)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xNcuafbb20Ub","colab_type":"text"},"source":["# 前処理"]},{"cell_type":"code","metadata":{"id":"Vq2ECX1W2c7K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598417285809,"user_tz":-540,"elapsed":74625,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}}},"source":["BATCH_SIZE = 64 # バッチサイズ\n","MAX_LENGTH = 60 # シーケンスの長さ\n","USE_TPU = False # TPUを使うか\n","BUFFER_SIZE = 50000"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUM_R_dd2c9q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598417289225,"user_tz":-540,"elapsed":78037,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}}},"source":["train_dataset = preprocess_utils.PreprocessData(\n","    mecab = MeCab.Tagger(\"-Ochasen\"),\n","    source_data = train_source,\n","    target_data = train_target,\n","    max_length = MAX_LENGTH,\n","    batch_size = BATCH_SIZE,\n","    test_flag = False,\n","    train_dataset = None,\n",")\n","\n","train_dataset.preprocess_data()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8Go0o6B2c_9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598417315494,"user_tz":-540,"elapsed":104303,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}}},"source":["if USE_TPU:\n","  tpu_grpc_url = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n","  tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n","  tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)\n","  tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)    \n","  strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)\n","\n","trainset = tf.data.Dataset.from_tensor_slices((train_dataset.source_vector, train_dataset.target_vector))\n","trainset = trainset.map(lambda source, target: (tf.cast(source, tf.int64), tf.cast(target, tf.int64))).shuffle(buffer_size=BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","if USE_TPU:\n","  trainset = strategy.experimental_distribute_dataset(trainset)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jtEwt4a327y3","colab_type":"text"},"source":["# モデル定義"]},{"cell_type":"code","metadata":{"id":"MaE0mWi82dEH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598417315495,"user_tz":-540,"elapsed":104301,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}}},"source":["num_layers=4 # レイヤー数\n","d_model=64 # 中間層の次元数\n","num_heads=4 # Multi Head Attentionのヘッド数\n","dff=2048 # Feed Forward Networkの次元数\n","dropout_rate = 0.1 # ドロップアウト率\n","\n","source_vocab_size = max(train_dataset.source_token.values()) + 1 # source文の語彙数\n","target_vocab_size = max(train_dataset.target_token.values()) + 1 # target文の語彙数"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pf3DBI_T2-Oq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598417315496,"user_tz":-540,"elapsed":104300,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}}},"source":["# 重み初期化\n","def initialize_weight(checkpoint_path, optimizer, transformer, max_length, batch_size, use_tpu=False):\n","\n","  if os.path.exists(checkpoint_path+'.pkl'):\n","    if use_tpu:\n","      number_of_tpu_cores = tpu_cluster_resolver.num_accelerators()['TPU']\n","      initialize_source, initialize_target = [[1]*max_length]*number_of_tpu_cores, [[1]*max_length]*number_of_tpu_cores\n","      initialize_set = tf.data.Dataset.from_tensor_slices((initialize_source, initialize_target))\n","      initialize_set = initialize_set.map(lambda source, target: (tf.cast(source, tf.int64), tf.cast(target, tf.int64))\n","          ).shuffle(buffer_size=BUFFER_SIZE).batch(batch_size).prefetch(\n","              buffer_size=tf.data.experimental.AUTOTUNE\n","          )\n","      initialize_set = strategy.experimental_distribute_dataset(initialize_set)\n","\n","      for inp, tar in initialize_set:\n","        distributed_train_on_batch(inp, tar)\n","\n","    else:\n","      initialize_set = tf.ones([batch_size, max_length], tf.int64)\n","      train_step(initialize_set, initialize_set)\n","    \n","    try:\n","      weight_utils.load_weights_from_pickle(checkpoint_path, optimizer, transformer)\n","    except:\n","      print('Failed to load checkpoints.')\n","\n","  else:\n","    print('No available checkpoints.')"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4I9b0rET3AgC","colab_type":"text"},"source":["# 学習実行"]},{"cell_type":"code","metadata":{"id":"wz9H29O_2-RU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598422075390,"user_tz":-540,"elapsed":4864190,"user":{"displayName":"demo hans-on","photoUrl":"","userId":"04377306958369458217"}},"outputId":"39e9e8c2-cd3c-4d9d-b291-e32ba6be3b74"},"source":["# Transformer\n","transformer = model.Transformer(num_layers, d_model, num_heads, dff,\n","                          source_vocab_size, target_vocab_size, \n","                          pe_input=source_vocab_size, \n","                          pe_target=target_vocab_size,\n","                          rate=dropout_rate)\n","\n","# Learning Rate\n","learning_rate = model.CustomSchedule(d_model)\n","\n","# Optimizer\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n","                                     epsilon=1e-9)\n","\n","# Loss\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","# Loss Function\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","  return tf.reduce_mean(loss_)\n","\n","# Metrics\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","# Checkpoint\n","checkpoint_path = \"/content/drive/My Drive/Transformer-master/checkpoints/gpu/model\"\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  \n","  enc_padding_mask, combined_mask, dec_padding_mask = model.create_masks(inp, tar_inp)\n","  \n","  with tf.GradientTape() as tape:\n","    predictions, _ = transformer(inp, tar_inp, \n","                                 True, \n","                                 enc_padding_mask, \n","                                 combined_mask, \n","                                 dec_padding_mask)\n","    loss = loss_function(tar_real, predictions)\n","\n","  gradients = tape.gradient(loss, transformer.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  \n","  train_loss(loss)\n","  train_accuracy(tar_real, predictions)\n","\n","# Initialize Weight\n","initialize_weight(checkpoint_path, optimizer, transformer, MAX_LENGTH, BATCH_SIZE, use_tpu=USE_TPU)\n","\n","EPOCHS = 30\n","batch = 0\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  for inp, tar in trainset:\n","    train_step(inp, tar)\n","    \n","    if batch % 50 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","      \n","    batch+=1\n","      \n","  if (epoch + 1) % 5 == 0:\n","    print('Saving checkpoint for epoch {} at {}'.format(epoch+1, checkpoint_path))\n","    weight_utils.save_weights_as_pickle(checkpoint_path, optimizer, transformer)\n","    \n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["No available checkpoints.\n","Epoch 1 Batch 0 Loss 1.7633 Accuracy 0.0026\n","Epoch 1 Batch 50 Loss 1.7469 Accuracy 0.0039\n","Epoch 1 Batch 100 Loss 1.7330 Accuracy 0.0099\n","Epoch 1 Batch 150 Loss 1.7105 Accuracy 0.0123\n","Epoch 1 Batch 200 Loss 1.6803 Accuracy 0.0141\n","Epoch 1 Batch 250 Loss 1.6523 Accuracy 0.0167\n","Epoch 1 Batch 300 Loss 1.6149 Accuracy 0.0190\n","Epoch 1 Batch 350 Loss 1.5769 Accuracy 0.0207\n","Epoch 1 Batch 400 Loss 1.5345 Accuracy 0.0219\n","Epoch 1 Batch 450 Loss 1.4918 Accuracy 0.0229\n","Epoch 1 Batch 500 Loss 1.4486 Accuracy 0.0237\n","Epoch 1 Batch 550 Loss 1.4089 Accuracy 0.0243\n","Epoch 1 Batch 600 Loss 1.3721 Accuracy 0.0251\n","Epoch 1 Batch 650 Loss 1.3382 Accuracy 0.0263\n","Epoch 1 Batch 700 Loss 1.3048 Accuracy 0.0278\n","Epoch 1 Batch 750 Loss 1.2733 Accuracy 0.0294\n","Epoch 1 Batch 800 Loss 1.2441 Accuracy 0.0310\n","Epoch 1 Loss 1.2299 Accuracy 0.0318\n","Time taken for 1 epoch: 176.3768208026886 secs\n","\n","Epoch 2 Batch 850 Loss 0.7708 Accuracy 0.0587\n","Epoch 2 Batch 900 Loss 0.7584 Accuracy 0.0601\n","Epoch 2 Batch 950 Loss 0.7461 Accuracy 0.0613\n","Epoch 2 Batch 1000 Loss 0.7363 Accuracy 0.0626\n","Epoch 2 Batch 1050 Loss 0.7266 Accuracy 0.0636\n","Epoch 2 Batch 1100 Loss 0.7196 Accuracy 0.0646\n","Epoch 2 Batch 1150 Loss 0.7146 Accuracy 0.0653\n","Epoch 2 Batch 1200 Loss 0.7090 Accuracy 0.0659\n","Epoch 2 Batch 1250 Loss 0.7046 Accuracy 0.0665\n","Epoch 2 Batch 1300 Loss 0.7016 Accuracy 0.0672\n","Epoch 2 Batch 1350 Loss 0.6966 Accuracy 0.0678\n","Epoch 2 Batch 1400 Loss 0.6926 Accuracy 0.0684\n","Epoch 2 Batch 1450 Loss 0.6890 Accuracy 0.0690\n","Epoch 2 Batch 1500 Loss 0.6859 Accuracy 0.0695\n","Epoch 2 Batch 1550 Loss 0.6816 Accuracy 0.0700\n","Epoch 2 Batch 1600 Loss 0.6784 Accuracy 0.0704\n","Epoch 2 Batch 1650 Loss 0.6755 Accuracy 0.0708\n","Epoch 2 Loss 0.6755 Accuracy 0.0708\n","Time taken for 1 epoch: 159.16777181625366 secs\n","\n","Epoch 3 Batch 1700 Loss 0.5982 Accuracy 0.0794\n","Epoch 3 Batch 1750 Loss 0.6003 Accuracy 0.0795\n","Epoch 3 Batch 1800 Loss 0.5990 Accuracy 0.0794\n","Epoch 3 Batch 1850 Loss 0.5979 Accuracy 0.0796\n","Epoch 3 Batch 1900 Loss 0.5952 Accuracy 0.0799\n","Epoch 3 Batch 1950 Loss 0.5941 Accuracy 0.0799\n","Epoch 3 Batch 2000 Loss 0.5939 Accuracy 0.0805\n","Epoch 3 Batch 2050 Loss 0.5917 Accuracy 0.0807\n","Epoch 3 Batch 2100 Loss 0.5917 Accuracy 0.0809\n","Epoch 3 Batch 2150 Loss 0.5898 Accuracy 0.0811\n","Epoch 3 Batch 2200 Loss 0.5886 Accuracy 0.0813\n","Epoch 3 Batch 2250 Loss 0.5873 Accuracy 0.0815\n","Epoch 3 Batch 2300 Loss 0.5859 Accuracy 0.0818\n","Epoch 3 Batch 2350 Loss 0.5854 Accuracy 0.0819\n","Epoch 3 Batch 2400 Loss 0.5834 Accuracy 0.0820\n","Epoch 3 Batch 2450 Loss 0.5815 Accuracy 0.0822\n","Epoch 3 Loss 0.5810 Accuracy 0.0823\n","Time taken for 1 epoch: 158.94134521484375 secs\n","\n","Epoch 4 Batch 2500 Loss 0.5256 Accuracy 0.0882\n","Epoch 4 Batch 2550 Loss 0.5240 Accuracy 0.0875\n","Epoch 4 Batch 2600 Loss 0.5276 Accuracy 0.0883\n","Epoch 4 Batch 2650 Loss 0.5261 Accuracy 0.0884\n","Epoch 4 Batch 2700 Loss 0.5235 Accuracy 0.0886\n","Epoch 4 Batch 2750 Loss 0.5240 Accuracy 0.0888\n","Epoch 4 Batch 2800 Loss 0.5242 Accuracy 0.0889\n","Epoch 4 Batch 2850 Loss 0.5245 Accuracy 0.0891\n","Epoch 4 Batch 2900 Loss 0.5236 Accuracy 0.0893\n","Epoch 4 Batch 2950 Loss 0.5224 Accuracy 0.0893\n","Epoch 4 Batch 3000 Loss 0.5204 Accuracy 0.0896\n","Epoch 4 Batch 3050 Loss 0.5191 Accuracy 0.0898\n","Epoch 4 Batch 3100 Loss 0.5187 Accuracy 0.0899\n","Epoch 4 Batch 3150 Loss 0.5174 Accuracy 0.0901\n","Epoch 4 Batch 3200 Loss 0.5160 Accuracy 0.0903\n","Epoch 4 Batch 3250 Loss 0.5145 Accuracy 0.0905\n","Epoch 4 Batch 3300 Loss 0.5129 Accuracy 0.0908\n","Epoch 4 Loss 0.5129 Accuracy 0.0908\n","Time taken for 1 epoch: 159.09367728233337 secs\n","\n","Epoch 5 Batch 3350 Loss 0.4560 Accuracy 0.0974\n","Epoch 5 Batch 3400 Loss 0.4533 Accuracy 0.0970\n","Epoch 5 Batch 3450 Loss 0.4594 Accuracy 0.0970\n","Epoch 5 Batch 3500 Loss 0.4603 Accuracy 0.0970\n","Epoch 5 Batch 3550 Loss 0.4587 Accuracy 0.0971\n","Epoch 5 Batch 3600 Loss 0.4587 Accuracy 0.0973\n","Epoch 5 Batch 3650 Loss 0.4590 Accuracy 0.0974\n","Epoch 5 Batch 3700 Loss 0.4595 Accuracy 0.0975\n","Epoch 5 Batch 3750 Loss 0.4584 Accuracy 0.0977\n","Epoch 5 Batch 3800 Loss 0.4587 Accuracy 0.0978\n","Epoch 5 Batch 3850 Loss 0.4577 Accuracy 0.0980\n","Epoch 5 Batch 3900 Loss 0.4574 Accuracy 0.0981\n","Epoch 5 Batch 3950 Loss 0.4565 Accuracy 0.0982\n","Epoch 5 Batch 4000 Loss 0.4557 Accuracy 0.0983\n","Epoch 5 Batch 4050 Loss 0.4550 Accuracy 0.0984\n","Epoch 5 Batch 4100 Loss 0.4541 Accuracy 0.0985\n","Saving checkpoint for epoch 5 at /content/drive/My Drive/Transformer-master/checkpoints/gpu/model\n","Save checkpoints\n","Epoch 5 Loss 0.4540 Accuracy 0.0986\n","Time taken for 1 epoch: 159.48754906654358 secs\n","\n","Epoch 6 Batch 4150 Loss 0.3996 Accuracy 0.1032\n","Epoch 6 Batch 4200 Loss 0.4021 Accuracy 0.1040\n","Epoch 6 Batch 4250 Loss 0.4058 Accuracy 0.1046\n","Epoch 6 Batch 4300 Loss 0.4069 Accuracy 0.1048\n","Epoch 6 Batch 4350 Loss 0.4077 Accuracy 0.1046\n","Epoch 6 Batch 4400 Loss 0.4096 Accuracy 0.1046\n","Epoch 6 Batch 4450 Loss 0.4094 Accuracy 0.1045\n","Epoch 6 Batch 4500 Loss 0.4086 Accuracy 0.1045\n","Epoch 6 Batch 4550 Loss 0.4079 Accuracy 0.1046\n","Epoch 6 Batch 4600 Loss 0.4088 Accuracy 0.1047\n","Epoch 6 Batch 4650 Loss 0.4080 Accuracy 0.1049\n","Epoch 6 Batch 4700 Loss 0.4068 Accuracy 0.1050\n","Epoch 6 Batch 4750 Loss 0.4063 Accuracy 0.1050\n","Epoch 6 Batch 4800 Loss 0.4062 Accuracy 0.1052\n","Epoch 6 Batch 4850 Loss 0.4060 Accuracy 0.1053\n","Epoch 6 Batch 4900 Loss 0.4055 Accuracy 0.1054\n","Epoch 6 Batch 4950 Loss 0.4051 Accuracy 0.1055\n","Epoch 6 Loss 0.4051 Accuracy 0.1056\n","Time taken for 1 epoch: 158.38601899147034 secs\n","\n","Epoch 7 Batch 5000 Loss 0.3582 Accuracy 0.1111\n","Epoch 7 Batch 5050 Loss 0.3610 Accuracy 0.1110\n","Epoch 7 Batch 5100 Loss 0.3611 Accuracy 0.1107\n","Epoch 7 Batch 5150 Loss 0.3643 Accuracy 0.1106\n","Epoch 7 Batch 5200 Loss 0.3639 Accuracy 0.1105\n","Epoch 7 Batch 5250 Loss 0.3639 Accuracy 0.1105\n","Epoch 7 Batch 5300 Loss 0.3651 Accuracy 0.1106\n","Epoch 7 Batch 5350 Loss 0.3667 Accuracy 0.1108\n","Epoch 7 Batch 5400 Loss 0.3672 Accuracy 0.1108\n","Epoch 7 Batch 5450 Loss 0.3672 Accuracy 0.1107\n","Epoch 7 Batch 5500 Loss 0.3671 Accuracy 0.1108\n","Epoch 7 Batch 5550 Loss 0.3668 Accuracy 0.1108\n","Epoch 7 Batch 5600 Loss 0.3673 Accuracy 0.1110\n","Epoch 7 Batch 5650 Loss 0.3671 Accuracy 0.1110\n","Epoch 7 Batch 5700 Loss 0.3674 Accuracy 0.1110\n","Epoch 7 Batch 5750 Loss 0.3674 Accuracy 0.1110\n","Epoch 7 Loss 0.3677 Accuracy 0.1110\n","Time taken for 1 epoch: 158.03217697143555 secs\n","\n","Epoch 8 Batch 5800 Loss 0.3279 Accuracy 0.1165\n","Epoch 8 Batch 5850 Loss 0.3300 Accuracy 0.1149\n","Epoch 8 Batch 5900 Loss 0.3355 Accuracy 0.1152\n","Epoch 8 Batch 5950 Loss 0.3346 Accuracy 0.1152\n","Epoch 8 Batch 6000 Loss 0.3354 Accuracy 0.1149\n","Epoch 8 Batch 6050 Loss 0.3362 Accuracy 0.1151\n","Epoch 8 Batch 6100 Loss 0.3365 Accuracy 0.1153\n","Epoch 8 Batch 6150 Loss 0.3371 Accuracy 0.1153\n","Epoch 8 Batch 6200 Loss 0.3373 Accuracy 0.1151\n","Epoch 8 Batch 6250 Loss 0.3387 Accuracy 0.1151\n","Epoch 8 Batch 6300 Loss 0.3397 Accuracy 0.1150\n","Epoch 8 Batch 6350 Loss 0.3398 Accuracy 0.1150\n","Epoch 8 Batch 6400 Loss 0.3412 Accuracy 0.1151\n","Epoch 8 Batch 6450 Loss 0.3421 Accuracy 0.1152\n","Epoch 8 Batch 6500 Loss 0.3420 Accuracy 0.1151\n","Epoch 8 Batch 6550 Loss 0.3422 Accuracy 0.1150\n","Epoch 8 Batch 6600 Loss 0.3428 Accuracy 0.1150\n","Epoch 8 Loss 0.3428 Accuracy 0.1150\n","Time taken for 1 epoch: 158.01940846443176 secs\n","\n","Epoch 9 Batch 6650 Loss 0.3099 Accuracy 0.1184\n","Epoch 9 Batch 6700 Loss 0.3099 Accuracy 0.1182\n","Epoch 9 Batch 6750 Loss 0.3120 Accuracy 0.1181\n","Epoch 9 Batch 6800 Loss 0.3139 Accuracy 0.1186\n","Epoch 9 Batch 6850 Loss 0.3138 Accuracy 0.1187\n","Epoch 9 Batch 6900 Loss 0.3152 Accuracy 0.1186\n","Epoch 9 Batch 6950 Loss 0.3160 Accuracy 0.1185\n","Epoch 9 Batch 7000 Loss 0.3171 Accuracy 0.1183\n","Epoch 9 Batch 7050 Loss 0.3177 Accuracy 0.1182\n","Epoch 9 Batch 7100 Loss 0.3189 Accuracy 0.1182\n","Epoch 9 Batch 7150 Loss 0.3203 Accuracy 0.1181\n","Epoch 9 Batch 7200 Loss 0.3206 Accuracy 0.1182\n","Epoch 9 Batch 7250 Loss 0.3212 Accuracy 0.1181\n","Epoch 9 Batch 7300 Loss 0.3220 Accuracy 0.1181\n","Epoch 9 Batch 7350 Loss 0.3228 Accuracy 0.1181\n","Epoch 9 Batch 7400 Loss 0.3235 Accuracy 0.1182\n","Epoch 9 Loss 0.3234 Accuracy 0.1182\n","Time taken for 1 epoch: 158.02721571922302 secs\n","\n","Epoch 10 Batch 7450 Loss 0.2838 Accuracy 0.1223\n","Epoch 10 Batch 7500 Loss 0.2953 Accuracy 0.1228\n","Epoch 10 Batch 7550 Loss 0.2937 Accuracy 0.1224\n","Epoch 10 Batch 7600 Loss 0.2964 Accuracy 0.1224\n","Epoch 10 Batch 7650 Loss 0.2976 Accuracy 0.1220\n","Epoch 10 Batch 7700 Loss 0.2988 Accuracy 0.1219\n","Epoch 10 Batch 7750 Loss 0.3000 Accuracy 0.1217\n","Epoch 10 Batch 7800 Loss 0.3007 Accuracy 0.1216\n","Epoch 10 Batch 7850 Loss 0.3016 Accuracy 0.1214\n","Epoch 10 Batch 7900 Loss 0.3019 Accuracy 0.1213\n","Epoch 10 Batch 7950 Loss 0.3038 Accuracy 0.1211\n","Epoch 10 Batch 8000 Loss 0.3045 Accuracy 0.1210\n","Epoch 10 Batch 8050 Loss 0.3051 Accuracy 0.1210\n","Epoch 10 Batch 8100 Loss 0.3054 Accuracy 0.1209\n","Epoch 10 Batch 8150 Loss 0.3062 Accuracy 0.1208\n","Epoch 10 Batch 8200 Loss 0.3069 Accuracy 0.1208\n","Epoch 10 Batch 8250 Loss 0.3079 Accuracy 0.1208\n","Saving checkpoint for epoch 10 at /content/drive/My Drive/Transformer-master/checkpoints/gpu/model\n","Save checkpoints\n","Epoch 10 Loss 0.3079 Accuracy 0.1208\n","Time taken for 1 epoch: 158.08975434303284 secs\n","\n","Epoch 11 Batch 8300 Loss 0.2735 Accuracy 0.1243\n","Epoch 11 Batch 8350 Loss 0.2763 Accuracy 0.1241\n","Epoch 11 Batch 8400 Loss 0.2788 Accuracy 0.1241\n","Epoch 11 Batch 8450 Loss 0.2816 Accuracy 0.1239\n","Epoch 11 Batch 8500 Loss 0.2833 Accuracy 0.1236\n","Epoch 11 Batch 8550 Loss 0.2849 Accuracy 0.1236\n","Epoch 11 Batch 8600 Loss 0.2866 Accuracy 0.1234\n","Epoch 11 Batch 8650 Loss 0.2874 Accuracy 0.1233\n","Epoch 11 Batch 8700 Loss 0.2886 Accuracy 0.1234\n","Epoch 11 Batch 8750 Loss 0.2905 Accuracy 0.1233\n","Epoch 11 Batch 8800 Loss 0.2915 Accuracy 0.1232\n","Epoch 11 Batch 8850 Loss 0.2919 Accuracy 0.1231\n","Epoch 11 Batch 8900 Loss 0.2924 Accuracy 0.1231\n","Epoch 11 Batch 8950 Loss 0.2926 Accuracy 0.1230\n","Epoch 11 Batch 9000 Loss 0.2929 Accuracy 0.1230\n","Epoch 11 Batch 9050 Loss 0.2940 Accuracy 0.1230\n","Epoch 11 Loss 0.2946 Accuracy 0.1229\n","Time taken for 1 epoch: 158.64418292045593 secs\n","\n","Epoch 12 Batch 9100 Loss 0.2585 Accuracy 0.1278\n","Epoch 12 Batch 9150 Loss 0.2697 Accuracy 0.1276\n","Epoch 12 Batch 9200 Loss 0.2725 Accuracy 0.1274\n","Epoch 12 Batch 9250 Loss 0.2734 Accuracy 0.1265\n","Epoch 12 Batch 9300 Loss 0.2749 Accuracy 0.1266\n","Epoch 12 Batch 9350 Loss 0.2753 Accuracy 0.1262\n","Epoch 12 Batch 9400 Loss 0.2765 Accuracy 0.1258\n","Epoch 12 Batch 9450 Loss 0.2766 Accuracy 0.1256\n","Epoch 12 Batch 9500 Loss 0.2772 Accuracy 0.1253\n","Epoch 12 Batch 9550 Loss 0.2777 Accuracy 0.1252\n","Epoch 12 Batch 9600 Loss 0.2786 Accuracy 0.1250\n","Epoch 12 Batch 9650 Loss 0.2796 Accuracy 0.1249\n","Epoch 12 Batch 9700 Loss 0.2808 Accuracy 0.1248\n","Epoch 12 Batch 9750 Loss 0.2810 Accuracy 0.1248\n","Epoch 12 Batch 9800 Loss 0.2819 Accuracy 0.1248\n","Epoch 12 Batch 9850 Loss 0.2830 Accuracy 0.1248\n","Epoch 12 Batch 9900 Loss 0.2835 Accuracy 0.1247\n","Epoch 12 Loss 0.2838 Accuracy 0.1247\n","Time taken for 1 epoch: 158.37301993370056 secs\n","\n","Epoch 13 Batch 9950 Loss 0.2556 Accuracy 0.1275\n","Epoch 13 Batch 10000 Loss 0.2562 Accuracy 0.1282\n","Epoch 13 Batch 10050 Loss 0.2599 Accuracy 0.1286\n","Epoch 13 Batch 10100 Loss 0.2614 Accuracy 0.1279\n","Epoch 13 Batch 10150 Loss 0.2633 Accuracy 0.1275\n","Epoch 13 Batch 10200 Loss 0.2634 Accuracy 0.1274\n","Epoch 13 Batch 10250 Loss 0.2641 Accuracy 0.1272\n","Epoch 13 Batch 10300 Loss 0.2657 Accuracy 0.1270\n","Epoch 13 Batch 10350 Loss 0.2672 Accuracy 0.1270\n","Epoch 13 Batch 10400 Loss 0.2683 Accuracy 0.1268\n","Epoch 13 Batch 10450 Loss 0.2694 Accuracy 0.1267\n","Epoch 13 Batch 10500 Loss 0.2708 Accuracy 0.1266\n","Epoch 13 Batch 10550 Loss 0.2717 Accuracy 0.1265\n","Epoch 13 Batch 10600 Loss 0.2725 Accuracy 0.1266\n","Epoch 13 Batch 10650 Loss 0.2734 Accuracy 0.1265\n","Epoch 13 Batch 10700 Loss 0.2738 Accuracy 0.1263\n","Epoch 13 Loss 0.2745 Accuracy 0.1263\n","Time taken for 1 epoch: 157.88012981414795 secs\n","\n","Epoch 14 Batch 10750 Loss 0.2563 Accuracy 0.1284\n","Epoch 14 Batch 10800 Loss 0.2496 Accuracy 0.1300\n","Epoch 14 Batch 10850 Loss 0.2491 Accuracy 0.1301\n","Epoch 14 Batch 10900 Loss 0.2522 Accuracy 0.1299\n","Epoch 14 Batch 10950 Loss 0.2532 Accuracy 0.1299\n","Epoch 14 Batch 11000 Loss 0.2544 Accuracy 0.1296\n","Epoch 14 Batch 11050 Loss 0.2547 Accuracy 0.1293\n","Epoch 14 Batch 11100 Loss 0.2560 Accuracy 0.1290\n","Epoch 14 Batch 11150 Loss 0.2571 Accuracy 0.1287\n","Epoch 14 Batch 11200 Loss 0.2583 Accuracy 0.1286\n","Epoch 14 Batch 11250 Loss 0.2598 Accuracy 0.1285\n","Epoch 14 Batch 11300 Loss 0.2606 Accuracy 0.1283\n","Epoch 14 Batch 11350 Loss 0.2620 Accuracy 0.1282\n","Epoch 14 Batch 11400 Loss 0.2640 Accuracy 0.1281\n","Epoch 14 Batch 11450 Loss 0.2651 Accuracy 0.1280\n","Epoch 14 Batch 11500 Loss 0.2654 Accuracy 0.1279\n","Epoch 14 Batch 11550 Loss 0.2661 Accuracy 0.1278\n","Epoch 14 Loss 0.2665 Accuracy 0.1278\n","Time taken for 1 epoch: 157.9897346496582 secs\n","\n","Epoch 15 Batch 11600 Loss 0.2382 Accuracy 0.1309\n","Epoch 15 Batch 11650 Loss 0.2438 Accuracy 0.1305\n","Epoch 15 Batch 11700 Loss 0.2427 Accuracy 0.1306\n","Epoch 15 Batch 11750 Loss 0.2448 Accuracy 0.1309\n","Epoch 15 Batch 11800 Loss 0.2456 Accuracy 0.1306\n","Epoch 15 Batch 11850 Loss 0.2480 Accuracy 0.1304\n","Epoch 15 Batch 11900 Loss 0.2493 Accuracy 0.1302\n","Epoch 15 Batch 11950 Loss 0.2501 Accuracy 0.1299\n","Epoch 15 Batch 12000 Loss 0.2511 Accuracy 0.1297\n","Epoch 15 Batch 12050 Loss 0.2527 Accuracy 0.1296\n","Epoch 15 Batch 12100 Loss 0.2535 Accuracy 0.1295\n","Epoch 15 Batch 12150 Loss 0.2543 Accuracy 0.1294\n","Epoch 15 Batch 12200 Loss 0.2552 Accuracy 0.1295\n","Epoch 15 Batch 12250 Loss 0.2563 Accuracy 0.1293\n","Epoch 15 Batch 12300 Loss 0.2575 Accuracy 0.1293\n","Epoch 15 Batch 12350 Loss 0.2582 Accuracy 0.1292\n","Saving checkpoint for epoch 15 at /content/drive/My Drive/Transformer-master/checkpoints/gpu/model\n","Save checkpoints\n","Epoch 15 Loss 0.2588 Accuracy 0.1291\n","Time taken for 1 epoch: 158.63299655914307 secs\n","\n","Epoch 16 Batch 12400 Loss 0.2190 Accuracy 0.1331\n","Epoch 16 Batch 12450 Loss 0.2301 Accuracy 0.1319\n","Epoch 16 Batch 12500 Loss 0.2332 Accuracy 0.1321\n","Epoch 16 Batch 12550 Loss 0.2347 Accuracy 0.1317\n","Epoch 16 Batch 12600 Loss 0.2374 Accuracy 0.1321\n","Epoch 16 Batch 12650 Loss 0.2389 Accuracy 0.1319\n","Epoch 16 Batch 12700 Loss 0.2406 Accuracy 0.1318\n","Epoch 16 Batch 12750 Loss 0.2418 Accuracy 0.1315\n","Epoch 16 Batch 12800 Loss 0.2434 Accuracy 0.1312\n","Epoch 16 Batch 12850 Loss 0.2449 Accuracy 0.1311\n","Epoch 16 Batch 12900 Loss 0.2462 Accuracy 0.1309\n","Epoch 16 Batch 12950 Loss 0.2476 Accuracy 0.1309\n","Epoch 16 Batch 13000 Loss 0.2486 Accuracy 0.1308\n","Epoch 16 Batch 13050 Loss 0.2497 Accuracy 0.1308\n","Epoch 16 Batch 13100 Loss 0.2502 Accuracy 0.1306\n","Epoch 16 Batch 13150 Loss 0.2515 Accuracy 0.1303\n","Epoch 16 Batch 13200 Loss 0.2524 Accuracy 0.1302\n","Epoch 16 Loss 0.2528 Accuracy 0.1302\n","Time taken for 1 epoch: 157.55022811889648 secs\n","\n","Epoch 17 Batch 13250 Loss 0.2222 Accuracy 0.1332\n","Epoch 17 Batch 13300 Loss 0.2258 Accuracy 0.1332\n","Epoch 17 Batch 13350 Loss 0.2289 Accuracy 0.1331\n","Epoch 17 Batch 13400 Loss 0.2297 Accuracy 0.1326\n","Epoch 17 Batch 13450 Loss 0.2311 Accuracy 0.1325\n","Epoch 17 Batch 13500 Loss 0.2329 Accuracy 0.1323\n","Epoch 17 Batch 13550 Loss 0.2347 Accuracy 0.1321\n","Epoch 17 Batch 13600 Loss 0.2365 Accuracy 0.1318\n","Epoch 17 Batch 13650 Loss 0.2384 Accuracy 0.1317\n","Epoch 17 Batch 13700 Loss 0.2401 Accuracy 0.1317\n","Epoch 17 Batch 13750 Loss 0.2419 Accuracy 0.1316\n","Epoch 17 Batch 13800 Loss 0.2431 Accuracy 0.1315\n","Epoch 17 Batch 13850 Loss 0.2438 Accuracy 0.1314\n","Epoch 17 Batch 13900 Loss 0.2443 Accuracy 0.1313\n","Epoch 17 Batch 13950 Loss 0.2456 Accuracy 0.1313\n","Epoch 17 Batch 14000 Loss 0.2466 Accuracy 0.1312\n","Epoch 17 Loss 0.2474 Accuracy 0.1312\n","Time taken for 1 epoch: 157.43239450454712 secs\n","\n","Epoch 18 Batch 14050 Loss 0.2189 Accuracy 0.1344\n","Epoch 18 Batch 14100 Loss 0.2223 Accuracy 0.1340\n","Epoch 18 Batch 14150 Loss 0.2255 Accuracy 0.1338\n","Epoch 18 Batch 14200 Loss 0.2265 Accuracy 0.1339\n","Epoch 18 Batch 14250 Loss 0.2279 Accuracy 0.1335\n","Epoch 18 Batch 14300 Loss 0.2295 Accuracy 0.1333\n","Epoch 18 Batch 14350 Loss 0.2315 Accuracy 0.1333\n","Epoch 18 Batch 14400 Loss 0.2328 Accuracy 0.1332\n","Epoch 18 Batch 14450 Loss 0.2336 Accuracy 0.1330\n","Epoch 18 Batch 14500 Loss 0.2350 Accuracy 0.1329\n","Epoch 18 Batch 14550 Loss 0.2360 Accuracy 0.1329\n","Epoch 18 Batch 14600 Loss 0.2367 Accuracy 0.1327\n","Epoch 18 Batch 14650 Loss 0.2379 Accuracy 0.1326\n","Epoch 18 Batch 14700 Loss 0.2395 Accuracy 0.1326\n","Epoch 18 Batch 14750 Loss 0.2402 Accuracy 0.1324\n","Epoch 18 Batch 14800 Loss 0.2411 Accuracy 0.1324\n","Epoch 18 Batch 14850 Loss 0.2422 Accuracy 0.1323\n","Epoch 18 Loss 0.2424 Accuracy 0.1323\n","Time taken for 1 epoch: 157.779367685318 secs\n","\n","Epoch 19 Batch 14900 Loss 0.2169 Accuracy 0.1371\n","Epoch 19 Batch 14950 Loss 0.2218 Accuracy 0.1370\n","Epoch 19 Batch 15000 Loss 0.2214 Accuracy 0.1360\n","Epoch 19 Batch 15050 Loss 0.2228 Accuracy 0.1352\n","Epoch 19 Batch 15100 Loss 0.2240 Accuracy 0.1351\n","Epoch 19 Batch 15150 Loss 0.2256 Accuracy 0.1349\n","Epoch 19 Batch 15200 Loss 0.2274 Accuracy 0.1347\n","Epoch 19 Batch 15250 Loss 0.2282 Accuracy 0.1346\n","Epoch 19 Batch 15300 Loss 0.2293 Accuracy 0.1343\n","Epoch 19 Batch 15350 Loss 0.2305 Accuracy 0.1341\n","Epoch 19 Batch 15400 Loss 0.2317 Accuracy 0.1340\n","Epoch 19 Batch 15450 Loss 0.2327 Accuracy 0.1337\n","Epoch 19 Batch 15500 Loss 0.2338 Accuracy 0.1336\n","Epoch 19 Batch 15550 Loss 0.2346 Accuracy 0.1335\n","Epoch 19 Batch 15600 Loss 0.2358 Accuracy 0.1334\n","Epoch 19 Batch 15650 Loss 0.2368 Accuracy 0.1332\n","Epoch 19 Loss 0.2377 Accuracy 0.1331\n","Time taken for 1 epoch: 156.71670126914978 secs\n","\n","Epoch 20 Batch 15700 Loss 0.2083 Accuracy 0.1272\n","Epoch 20 Batch 15750 Loss 0.2094 Accuracy 0.1346\n","Epoch 20 Batch 15800 Loss 0.2117 Accuracy 0.1347\n","Epoch 20 Batch 15850 Loss 0.2140 Accuracy 0.1347\n","Epoch 20 Batch 15900 Loss 0.2160 Accuracy 0.1345\n","Epoch 20 Batch 15950 Loss 0.2194 Accuracy 0.1345\n","Epoch 20 Batch 16000 Loss 0.2217 Accuracy 0.1342\n","Epoch 20 Batch 16050 Loss 0.2233 Accuracy 0.1342\n","Epoch 20 Batch 16100 Loss 0.2248 Accuracy 0.1344\n","Epoch 20 Batch 16150 Loss 0.2274 Accuracy 0.1343\n","Epoch 20 Batch 16200 Loss 0.2289 Accuracy 0.1344\n","Epoch 20 Batch 16250 Loss 0.2296 Accuracy 0.1343\n","Epoch 20 Batch 16300 Loss 0.2303 Accuracy 0.1342\n","Epoch 20 Batch 16350 Loss 0.2311 Accuracy 0.1342\n","Epoch 20 Batch 16400 Loss 0.2314 Accuracy 0.1340\n","Epoch 20 Batch 16450 Loss 0.2322 Accuracy 0.1339\n","Epoch 20 Batch 16500 Loss 0.2332 Accuracy 0.1337\n","Saving checkpoint for epoch 20 at /content/drive/My Drive/Transformer-master/checkpoints/gpu/model\n","Save checkpoints\n","Epoch 20 Loss 0.2337 Accuracy 0.1337\n","Time taken for 1 epoch: 157.78202724456787 secs\n","\n","Epoch 21 Batch 16550 Loss 0.2107 Accuracy 0.1348\n","Epoch 21 Batch 16600 Loss 0.2119 Accuracy 0.1361\n","Epoch 21 Batch 16650 Loss 0.2109 Accuracy 0.1360\n","Epoch 21 Batch 16700 Loss 0.2117 Accuracy 0.1361\n","Epoch 21 Batch 16750 Loss 0.2131 Accuracy 0.1359\n","Epoch 21 Batch 16800 Loss 0.2165 Accuracy 0.1361\n","Epoch 21 Batch 16850 Loss 0.2182 Accuracy 0.1359\n","Epoch 21 Batch 16900 Loss 0.2199 Accuracy 0.1356\n","Epoch 21 Batch 16950 Loss 0.2218 Accuracy 0.1356\n","Epoch 21 Batch 17000 Loss 0.2230 Accuracy 0.1354\n","Epoch 21 Batch 17050 Loss 0.2241 Accuracy 0.1353\n","Epoch 21 Batch 17100 Loss 0.2247 Accuracy 0.1352\n","Epoch 21 Batch 17150 Loss 0.2259 Accuracy 0.1350\n","Epoch 21 Batch 17200 Loss 0.2272 Accuracy 0.1349\n","Epoch 21 Batch 17250 Loss 0.2283 Accuracy 0.1348\n","Epoch 21 Batch 17300 Loss 0.2291 Accuracy 0.1347\n","Epoch 21 Loss 0.2297 Accuracy 0.1346\n","Time taken for 1 epoch: 157.69837307929993 secs\n","\n","Epoch 22 Batch 17350 Loss 0.1986 Accuracy 0.1367\n","Epoch 22 Batch 17400 Loss 0.2057 Accuracy 0.1377\n","Epoch 22 Batch 17450 Loss 0.2050 Accuracy 0.1369\n","Epoch 22 Batch 17500 Loss 0.2084 Accuracy 0.1372\n","Epoch 22 Batch 17550 Loss 0.2113 Accuracy 0.1368\n","Epoch 22 Batch 17600 Loss 0.2129 Accuracy 0.1366\n","Epoch 22 Batch 17650 Loss 0.2134 Accuracy 0.1365\n","Epoch 22 Batch 17700 Loss 0.2147 Accuracy 0.1363\n","Epoch 22 Batch 17750 Loss 0.2163 Accuracy 0.1362\n","Epoch 22 Batch 17800 Loss 0.2174 Accuracy 0.1361\n","Epoch 22 Batch 17850 Loss 0.2195 Accuracy 0.1359\n","Epoch 22 Batch 17900 Loss 0.2207 Accuracy 0.1358\n","Epoch 22 Batch 17950 Loss 0.2223 Accuracy 0.1357\n","Epoch 22 Batch 18000 Loss 0.2234 Accuracy 0.1356\n","Epoch 22 Batch 18050 Loss 0.2243 Accuracy 0.1355\n","Epoch 22 Batch 18100 Loss 0.2253 Accuracy 0.1354\n","Epoch 22 Batch 18150 Loss 0.2261 Accuracy 0.1352\n","Epoch 22 Loss 0.2263 Accuracy 0.1351\n","Time taken for 1 epoch: 157.4754238128662 secs\n","\n","Epoch 23 Batch 18200 Loss 0.2044 Accuracy 0.1395\n","Epoch 23 Batch 18250 Loss 0.2043 Accuracy 0.1380\n","Epoch 23 Batch 18300 Loss 0.2049 Accuracy 0.1374\n","Epoch 23 Batch 18350 Loss 0.2058 Accuracy 0.1372\n","Epoch 23 Batch 18400 Loss 0.2079 Accuracy 0.1373\n","Epoch 23 Batch 18450 Loss 0.2098 Accuracy 0.1372\n","Epoch 23 Batch 18500 Loss 0.2113 Accuracy 0.1370\n","Epoch 23 Batch 18550 Loss 0.2124 Accuracy 0.1367\n","Epoch 23 Batch 18600 Loss 0.2138 Accuracy 0.1366\n","Epoch 23 Batch 18650 Loss 0.2150 Accuracy 0.1365\n","Epoch 23 Batch 18700 Loss 0.2162 Accuracy 0.1363\n","Epoch 23 Batch 18750 Loss 0.2182 Accuracy 0.1363\n","Epoch 23 Batch 18800 Loss 0.2191 Accuracy 0.1362\n","Epoch 23 Batch 18850 Loss 0.2202 Accuracy 0.1361\n","Epoch 23 Batch 18900 Loss 0.2212 Accuracy 0.1360\n","Epoch 23 Batch 18950 Loss 0.2219 Accuracy 0.1359\n","Epoch 23 Loss 0.2227 Accuracy 0.1359\n","Time taken for 1 epoch: 157.63633251190186 secs\n","\n","Epoch 24 Batch 19000 Loss 0.1977 Accuracy 0.1370\n","Epoch 24 Batch 19050 Loss 0.2019 Accuracy 0.1404\n","Epoch 24 Batch 19100 Loss 0.1998 Accuracy 0.1396\n","Epoch 24 Batch 19150 Loss 0.2027 Accuracy 0.1389\n","Epoch 24 Batch 19200 Loss 0.2038 Accuracy 0.1384\n","Epoch 24 Batch 19250 Loss 0.2051 Accuracy 0.1382\n","Epoch 24 Batch 19300 Loss 0.2079 Accuracy 0.1381\n","Epoch 24 Batch 19350 Loss 0.2096 Accuracy 0.1381\n","Epoch 24 Batch 19400 Loss 0.2112 Accuracy 0.1378\n","Epoch 24 Batch 19450 Loss 0.2121 Accuracy 0.1375\n","Epoch 24 Batch 19500 Loss 0.2131 Accuracy 0.1372\n","Epoch 24 Batch 19550 Loss 0.2140 Accuracy 0.1370\n","Epoch 24 Batch 19600 Loss 0.2149 Accuracy 0.1368\n","Epoch 24 Batch 19650 Loss 0.2165 Accuracy 0.1367\n","Epoch 24 Batch 19700 Loss 0.2172 Accuracy 0.1367\n","Epoch 24 Batch 19750 Loss 0.2182 Accuracy 0.1366\n","Epoch 24 Batch 19800 Loss 0.2193 Accuracy 0.1364\n","Epoch 24 Loss 0.2198 Accuracy 0.1364\n","Time taken for 1 epoch: 157.39756274223328 secs\n","\n","Epoch 25 Batch 19850 Loss 0.1847 Accuracy 0.1372\n","Epoch 25 Batch 19900 Loss 0.1915 Accuracy 0.1390\n","Epoch 25 Batch 19950 Loss 0.1969 Accuracy 0.1382\n","Epoch 25 Batch 20000 Loss 0.1984 Accuracy 0.1380\n","Epoch 25 Batch 20050 Loss 0.1999 Accuracy 0.1380\n","Epoch 25 Batch 20100 Loss 0.2032 Accuracy 0.1382\n","Epoch 25 Batch 20150 Loss 0.2045 Accuracy 0.1378\n","Epoch 25 Batch 20200 Loss 0.2063 Accuracy 0.1378\n","Epoch 25 Batch 20250 Loss 0.2075 Accuracy 0.1377\n","Epoch 25 Batch 20300 Loss 0.2086 Accuracy 0.1375\n","Epoch 25 Batch 20350 Loss 0.2099 Accuracy 0.1374\n","Epoch 25 Batch 20400 Loss 0.2110 Accuracy 0.1373\n","Epoch 25 Batch 20450 Loss 0.2123 Accuracy 0.1373\n","Epoch 25 Batch 20500 Loss 0.2134 Accuracy 0.1371\n","Epoch 25 Batch 20550 Loss 0.2148 Accuracy 0.1372\n","Epoch 25 Batch 20600 Loss 0.2163 Accuracy 0.1372\n","Saving checkpoint for epoch 25 at /content/drive/My Drive/Transformer-master/checkpoints/gpu/model\n","Save checkpoints\n","Epoch 25 Loss 0.2169 Accuracy 0.1372\n","Time taken for 1 epoch: 157.72535729408264 secs\n","\n","Epoch 26 Batch 20650 Loss 0.1850 Accuracy 0.1337\n","Epoch 26 Batch 20700 Loss 0.1961 Accuracy 0.1394\n","Epoch 26 Batch 20750 Loss 0.1991 Accuracy 0.1394\n","Epoch 26 Batch 20800 Loss 0.1975 Accuracy 0.1393\n","Epoch 26 Batch 20850 Loss 0.1999 Accuracy 0.1394\n","Epoch 26 Batch 20900 Loss 0.2012 Accuracy 0.1391\n","Epoch 26 Batch 20950 Loss 0.2019 Accuracy 0.1390\n","Epoch 26 Batch 21000 Loss 0.2041 Accuracy 0.1386\n","Epoch 26 Batch 21050 Loss 0.2052 Accuracy 0.1385\n","Epoch 26 Batch 21100 Loss 0.2063 Accuracy 0.1384\n","Epoch 26 Batch 21150 Loss 0.2070 Accuracy 0.1382\n","Epoch 26 Batch 21200 Loss 0.2081 Accuracy 0.1380\n","Epoch 26 Batch 21250 Loss 0.2092 Accuracy 0.1380\n","Epoch 26 Batch 21300 Loss 0.2108 Accuracy 0.1379\n","Epoch 26 Batch 21350 Loss 0.2118 Accuracy 0.1377\n","Epoch 26 Batch 21400 Loss 0.2129 Accuracy 0.1377\n","Epoch 26 Batch 21450 Loss 0.2139 Accuracy 0.1375\n","Epoch 26 Loss 0.2146 Accuracy 0.1374\n","Time taken for 1 epoch: 157.9600477218628 secs\n","\n","Epoch 27 Batch 21500 Loss 0.1900 Accuracy 0.1394\n","Epoch 27 Batch 21550 Loss 0.1924 Accuracy 0.1402\n","Epoch 27 Batch 21600 Loss 0.1934 Accuracy 0.1395\n","Epoch 27 Batch 21650 Loss 0.1950 Accuracy 0.1397\n","Epoch 27 Batch 21700 Loss 0.1964 Accuracy 0.1392\n","Epoch 27 Batch 21750 Loss 0.1983 Accuracy 0.1392\n","Epoch 27 Batch 21800 Loss 0.1997 Accuracy 0.1391\n","Epoch 27 Batch 21850 Loss 0.2017 Accuracy 0.1390\n","Epoch 27 Batch 21900 Loss 0.2026 Accuracy 0.1387\n","Epoch 27 Batch 21950 Loss 0.2046 Accuracy 0.1387\n","Epoch 27 Batch 22000 Loss 0.2055 Accuracy 0.1385\n","Epoch 27 Batch 22050 Loss 0.2068 Accuracy 0.1384\n","Epoch 27 Batch 22100 Loss 0.2077 Accuracy 0.1383\n","Epoch 27 Batch 22150 Loss 0.2090 Accuracy 0.1382\n","Epoch 27 Batch 22200 Loss 0.2096 Accuracy 0.1381\n","Epoch 27 Batch 22250 Loss 0.2107 Accuracy 0.1380\n","Epoch 27 Batch 22300 Loss 0.2117 Accuracy 0.1380\n","Epoch 27 Loss 0.2118 Accuracy 0.1380\n","Time taken for 1 epoch: 157.35712361335754 secs\n","\n","Epoch 28 Batch 22350 Loss 0.1868 Accuracy 0.1417\n","Epoch 28 Batch 22400 Loss 0.1869 Accuracy 0.1411\n","Epoch 28 Batch 22450 Loss 0.1898 Accuracy 0.1403\n","Epoch 28 Batch 22500 Loss 0.1918 Accuracy 0.1404\n","Epoch 28 Batch 22550 Loss 0.1942 Accuracy 0.1403\n","Epoch 28 Batch 22600 Loss 0.1956 Accuracy 0.1400\n","Epoch 28 Batch 22650 Loss 0.1968 Accuracy 0.1398\n","Epoch 28 Batch 22700 Loss 0.1988 Accuracy 0.1397\n","Epoch 28 Batch 22750 Loss 0.2004 Accuracy 0.1396\n","Epoch 28 Batch 22800 Loss 0.2018 Accuracy 0.1395\n","Epoch 28 Batch 22850 Loss 0.2035 Accuracy 0.1393\n","Epoch 28 Batch 22900 Loss 0.2045 Accuracy 0.1392\n","Epoch 28 Batch 22950 Loss 0.2056 Accuracy 0.1390\n","Epoch 28 Batch 23000 Loss 0.2063 Accuracy 0.1388\n","Epoch 28 Batch 23050 Loss 0.2076 Accuracy 0.1387\n","Epoch 28 Batch 23100 Loss 0.2084 Accuracy 0.1387\n","Epoch 28 Loss 0.2090 Accuracy 0.1386\n","Time taken for 1 epoch: 157.8477418422699 secs\n","\n","Epoch 29 Batch 23150 Loss 0.1946 Accuracy 0.1409\n","Epoch 29 Batch 23200 Loss 0.1903 Accuracy 0.1419\n","Epoch 29 Batch 23250 Loss 0.1919 Accuracy 0.1414\n","Epoch 29 Batch 23300 Loss 0.1925 Accuracy 0.1413\n","Epoch 29 Batch 23350 Loss 0.1934 Accuracy 0.1412\n","Epoch 29 Batch 23400 Loss 0.1954 Accuracy 0.1407\n","Epoch 29 Batch 23450 Loss 0.1959 Accuracy 0.1404\n","Epoch 29 Batch 23500 Loss 0.1973 Accuracy 0.1404\n","Epoch 29 Batch 23550 Loss 0.1988 Accuracy 0.1400\n","Epoch 29 Batch 23600 Loss 0.1993 Accuracy 0.1398\n","Epoch 29 Batch 23650 Loss 0.2007 Accuracy 0.1397\n","Epoch 29 Batch 23700 Loss 0.2012 Accuracy 0.1397\n","Epoch 29 Batch 23750 Loss 0.2024 Accuracy 0.1395\n","Epoch 29 Batch 23800 Loss 0.2036 Accuracy 0.1395\n","Epoch 29 Batch 23850 Loss 0.2046 Accuracy 0.1393\n","Epoch 29 Batch 23900 Loss 0.2054 Accuracy 0.1392\n","Epoch 29 Batch 23950 Loss 0.2067 Accuracy 0.1391\n","Epoch 29 Loss 0.2068 Accuracy 0.1391\n","Time taken for 1 epoch: 157.7066831588745 secs\n","\n","Epoch 30 Batch 24000 Loss 0.1764 Accuracy 0.1405\n","Epoch 30 Batch 24050 Loss 0.1826 Accuracy 0.1402\n","Epoch 30 Batch 24100 Loss 0.1856 Accuracy 0.1406\n","Epoch 30 Batch 24150 Loss 0.1880 Accuracy 0.1405\n","Epoch 30 Batch 24200 Loss 0.1896 Accuracy 0.1406\n","Epoch 30 Batch 24250 Loss 0.1908 Accuracy 0.1407\n","Epoch 30 Batch 24300 Loss 0.1933 Accuracy 0.1406\n","Epoch 30 Batch 24350 Loss 0.1953 Accuracy 0.1404\n","Epoch 30 Batch 24400 Loss 0.1962 Accuracy 0.1404\n","Epoch 30 Batch 24450 Loss 0.1975 Accuracy 0.1403\n","Epoch 30 Batch 24500 Loss 0.1988 Accuracy 0.1401\n","Epoch 30 Batch 24550 Loss 0.1996 Accuracy 0.1399\n","Epoch 30 Batch 24600 Loss 0.2003 Accuracy 0.1398\n","Epoch 30 Batch 24650 Loss 0.2016 Accuracy 0.1396\n","Epoch 30 Batch 24700 Loss 0.2027 Accuracy 0.1395\n","Epoch 30 Batch 24750 Loss 0.2042 Accuracy 0.1394\n","Saving checkpoint for epoch 30 at /content/drive/My Drive/Transformer-master/checkpoints/gpu/model\n","Save checkpoints\n","Epoch 30 Loss 0.2050 Accuracy 0.1394\n","Time taken for 1 epoch: 158.13982605934143 secs\n","\n"],"name":"stdout"}]}]}